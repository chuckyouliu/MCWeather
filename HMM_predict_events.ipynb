{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datascrape as ds\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ds.munis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/municipalities.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get data of munis from 1960\n",
    "for muni in ds.munis:\n",
    "    print(muni)\n",
    "    ds.fetch_data(muni, date(1960, 1, 1), date(2015, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = ds.fetch_data(\"KBOS\", date(1960, 1, 1), date(2014, 12, 31))\n",
    "# print(len(df.index))\n",
    "# print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[\" Events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns dictionary of df's of municipalities with the intersection of available dates\n",
    "dd = ds.dictdf(ds.munis, date(1973, 1, 1), date(1973, 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for muni, df in dd.items():\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dd[\"KORH\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd = ds.dictdf(ds.munis, date(1960, 1, 1), date(2015, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for muni, df in dd.items():\n",
    "    print(muni, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[df.index != '1968-9-14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2nd order HMM\n",
    "- period of data collection -- Jan 1 1960 to Dec 31 2000\n",
    "    \n",
    "Outputs - \n",
    "- Period of prediction 2015 - day to day\n",
    "- Period of prediction - major events - decade of 2000\n",
    "- Hurricane Sandy, Boston Winter of 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import math\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract data\n",
    "df = ds.fetch_data(\"KBOS\", date(1960, 1, 1), date(2010, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Substitute nans with \"noinfo\" in the Events field\n",
    "def replace_NaNs(df):\n",
    "    for i in range(len(df)):\n",
    "        if isinstance(df.iloc[i][\" Events\"], float):\n",
    "            if math.isnan(df.iloc[i][\" Events\"]):\n",
    "                df.set_value(df.iloc[i].name, \" Events\", \"noinfo\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data cleanup\n",
    "# drop the one row with all NaNs in the data - '1968-9-14'\n",
    "df = df[df.index != '1968-9-14']\n",
    "# impute values for the few other NaNs we care about\n",
    "df.set_value(\"2000-8-22\", \"Mean TemperatureF\", 73) \n",
    "df.set_value(\"2000-6-9\", \"Mean TemperatureF\", 75)\n",
    "df.set_value(\"1972-8-11\", \" Max VisibilityMiles\", 17.5)\n",
    "df.set_value(\"1972-8-11\", \" Mean VisibilityMiles\", 16)\n",
    "df.set_value(\"1972-8-11\", \" Min VisibilityMiles\", 12.5)\n",
    "# Substitute nans with \"noinfo\" in the Events field\n",
    "replace_NaNs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noinfo',\n",
       " 'Fog-Rain',\n",
       " 'Snow',\n",
       " 'Fog-Snow',\n",
       " 'Fog',\n",
       " 'Rain-Snow',\n",
       " 'Fog-Rain-Snow',\n",
       " 'Rain',\n",
       " 'Fog-Rain-Thunderstorm',\n",
       " 'Fog-Rain-Snow-Thunderstorm',\n",
       " 'Rain-Thunderstorm',\n",
       " 'Rain-Snow-Thunderstorm',\n",
       " 'Fog-Snow-Thunderstorm',\n",
       " 'Thunderstorm',\n",
       " 'Fog-Thunderstorm',\n",
       " 'Fog-Rain-Snow-Hail-Thunderstorm',\n",
       " 'Fog-Rain-Hail-Thunderstorm',\n",
       " 'Tornado',\n",
       " 'Rain-Hail-Thunderstorm']"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[\" Events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "no_distinct_events = 9 #len(df[\" Events\"].unique()) (suppressing all thunderstorm events into one)\n",
    "event_list = list(df[\" Events\"].unique())\n",
    "params = ['Mean TemperatureF',\n",
    "          'MeanDew PointF',\n",
    "          ' Mean Humidity',\n",
    "          ' Mean Sea Level PressureIn',\n",
    "          ' Mean VisibilityMiles',\n",
    "          ' Mean Wind SpeedMPH',\n",
    "          'PrecipitationIn']\n",
    "no_emission_params = len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# collapsing all thunderstorm events into one thunderstorm event bucket; (1 tornado day also included)\n",
    "def convert_event_to_int(event):\n",
    "    idx = event_list.index(event)\n",
    "    if idx > 7:\n",
    "        return 8\n",
    "    else:\n",
    "        return idx\n",
    "\n",
    "def convert_int_to_event(intt):\n",
    "    if intt < 8:\n",
    "        return event_list[intt]\n",
    "    else:\n",
    "        return \"Thunderstorm\"\n",
    "\n",
    "def normalize(matrix):\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix[i] = matrix[i]/float(sum(matrix[i]))\n",
    "    return matrix\n",
    "\n",
    "def normalize_3d(matrix):\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            matrix[i, j] = matrix[i, j]/float(sum(matrix[i, j]))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constructing Transition prob matrix for second order HMM\n",
    "# 9 distinct event states between 1960 and 2010\n",
    "\n",
    "TP = np.ones((no_distinct_events, no_distinct_events))\n",
    "\n",
    "for i in range(len(df) - 1):        \n",
    "    state_i = convert_event_to_int(df.iloc[i][\" Events\"])\n",
    "    to_state = convert_event_to_int(df.iloc[i+1][\" Events\"])\n",
    "    TP2[state_i, to_state] += 1\n",
    "\n",
    "TP2 = np.ones((no_distinct_events, no_distinct_events, no_distinct_events))\n",
    "\n",
    "for i in range(len(df) - 2):        \n",
    "    state_i_minus_1 = convert_event_to_int(df.iloc[i][\" Events\"])\n",
    "    state_i = convert_event_to_int(df.iloc[i+1][\" Events\"])\n",
    "    to_state = convert_event_to_int(df.iloc[i+2][\" Events\"])\n",
    "    TP2[state_i_minus_1, state_i, to_state] += 1\n",
    "\n",
    "TP = normalize(TP)\n",
    "TP2 = normalize_3d(TP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constructing the Emission prob matrix\n",
    "\n",
    "# Gather raw data to compute EP distribution parameters\n",
    "EP_data = {}\n",
    "for event in event_list:\n",
    "    EP_data[convert_event_to_int(event)] = {}\n",
    "    for param in params:\n",
    "        EP_data[convert_event_to_int(event)][param] = []\n",
    "        \n",
    "for i in range(len(df)):\n",
    "    state = convert_event_to_int(df.iloc[i][\" Events\"])\n",
    "    for param in params:\n",
    "        val = df.iloc[i][param]\n",
    "        if param == 'PrecipitationIn':\n",
    "            if val == 0:  # Precipitation is modeled as lognormal distribution, hence no zeros\n",
    "                val = 0.0025\n",
    "            EP_data[state][param].append(np.log(val))\n",
    "        else: \n",
    "            EP_data[state][param].append(val)\n",
    "\n",
    "\n",
    "# calculate distribution parameters for EP\n",
    "EP_dist_params = {}\n",
    "for event in event_list:\n",
    "    state = convert_event_to_int(event)\n",
    "    EP_dist_params[state] = {}\n",
    "    EP_dist_params[state][\"mean\"] = [np.array(EP_data[state][param]).mean() for param in params]\n",
    "    EP_dist_params[state][\"covariance\"] = np.cov(np.array([EP_data[state][param] for param in params]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_EP(obs_vector, state):\n",
    "    obs_vector_init = obs_vector[0:6] \n",
    "    if obs_vector[6] == 0:\n",
    "        obs_vector[6] = 0.0025\n",
    "    obs_vector = np.append(obs_vector_init, np.log(obs_vector[6]))\n",
    "    EP_prob = scipy.stats.multivariate_normal.pdf(obs_vector, EP_dist_params[state][\"mean\"],\n",
    "                                                  EP_dist_params[state][\"covariance\"])\n",
    "    return EP_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot params across event types to confirm that a gaussian is a reasonable assumption\n",
    "# Modeling precipitation alone as a lognormal as that makes more sense\n",
    "for e in range(9):\n",
    "    for i in range(7):\n",
    "        if i == 6:\n",
    "            #print(np.array(np.log(EP_data[e][params[i]])).mean())\n",
    "            plt.hist(EP_data[e][params[i]])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.hist(EP_data[e][params[i]])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99     0.00125  0.00125  0.00125  0.00125  0.00125  0.00125  0.00125\n",
      "  0.00125]\n"
     ]
    }
   ],
   "source": [
    "# compute IP\n",
    "# Initial prob\n",
    "IP = np.zeros(no_distinct_events)\n",
    "for i in range(no_distinct_events):\n",
    "    IP[i] = 0.01/(no_distinct_events - 1)\n",
    "IP[0] = 0.99 # Jan 1 2015 happens to be a noinfo day\n",
    "print IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(df[\" Events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Viterbi - second order HMM with log probabilities\n",
    "def viterbi_log_second(IP, TP2, TP, EP, X):\n",
    "    Z_inferred = np.empty(len(X)) #, dtype = \"string\")\n",
    "    Z_state_ind = np.empty(len(X))\n",
    "    T1 = np.zeros((9, 9, len(X)))\n",
    "    T2 = np.zeros((9, 9, len(X)))\n",
    "    IP_T1 = np.zeros(9)\n",
    "    \n",
    "    for i in range(9):\n",
    "        IP_T1[i] = np.log10(IP[i]) + np.log10(compute_EP(np.array(X.iloc[0]), i))\n",
    "        T2[i, 0] = -1 \n",
    "\n",
    "    for i in range(9):\n",
    "        max_prob = float(\"-inf\")\n",
    "        for j in range(9):\n",
    "            T1[j, i, 1] = IP_T1[j] + np.log10(TP[j, i]) + np.log10(compute_EP(np.array(X.iloc[1]), i))\n",
    "            T2[j, i, 1] = -1\n",
    "    \n",
    "    for i in range(2, len(X)):\n",
    "        if i%100 == 0:\n",
    "            print i\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                max_prob = float(\"-inf\")\n",
    "                ind = 0\n",
    "                for l in range(9):\n",
    "                    prob = T1[l, k, i-1] + np.log10(TP2[l, k, j]) \\\n",
    "                           + np.log10(compute_EP(np.array(X.iloc[i]), j))\n",
    "                    #print prob\n",
    "                    if max_prob < prob:\n",
    "                        max_prob = prob\n",
    "                        ind = l\n",
    "                T1[k, j, i] = max_prob\n",
    "                T2[k, j, i] = ind\n",
    "            \n",
    "    #print T1\n",
    "#     print \"hi\"\n",
    "#     print T2\n",
    "    final_state_ind = np.argmax(T1[:, :, len(X) - 1])\n",
    "    Z_state_ind[len(X) - 1] = final_state_ind%9\n",
    "    Z_state_ind[len(X) - 2] = final_state_ind/9\n",
    "    \n",
    "    Z_inferred[len(X) - 1] = Z_state_ind[len(X) - 1] #convert_int_to_event(int(Z_state_ind[len(X) - 1]))\n",
    "    Z_inferred[len(X) - 2] = Z_state_ind[len(X) - 2] #convert_int_to_event(int(Z_state_ind[len(X) - 2]))\n",
    "    for i in reversed(range(2, len(X))):\n",
    "        Z_state_ind[i-2] = int(T2[Z_state_ind[i-1], Z_state_ind[i], i])\n",
    "        Z_inferred[i-2] = Z_state_ind[i-2] #convert_int_to_event(int(Z_state_ind[i-2]))\n",
    "        \n",
    "    Z_inferred_event = []\n",
    "    for i in range(len(X)):\n",
    "        Z_inferred_event.append(convert_int_to_event(int(Z_inferred[i])))\n",
    "    return Z_inferred_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2015 = ds.fetch_data(\"KBOS\", date(2011, 1, 1), date(2015, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_NaNs(df_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinaysubbiah/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:45: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "EP = []\n",
    "l = 30\n",
    "Z_inferred = viterbi_log_second(IP, TP2, TP, EP, df_2015[params])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(inferred, original, specific_target=None):\n",
    "    assert len(inferred) == len(original)\n",
    "    mistake_count = 0\n",
    "    total_count = 0\n",
    "    for i in range(len(original)):\n",
    "        if specific_target is None:\n",
    "            total_count += 1\n",
    "            if inferred[i] != original[i] and (inferred[i] != \"Thunderstorm\" or original[i].find(\"Thunderstorm\") == -1):\n",
    "                mistake_count += 1\n",
    "        else:\n",
    "            if original[i] == specific_target or \\\n",
    "              (specific_target == \"Thunderstorm\" and original[i].find(specific_target) != -1):\n",
    "                total_count += 1\n",
    "                if inferred[i] != original[i] and (inferred[i] != \"Thunderstorm\" or original[i].find(\"Thunderstorm\") == -1):\n",
    "                    mistake_count += 1\n",
    "                \n",
    "    percentage_accurate = 1 - mistake_count/float(total_count)\n",
    "    return mistake_count, percentage_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thunderstorm\n"
     ]
    }
   ],
   "source": [
    "print Z_inferred[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(Z_inferred)):\n",
    "    if Z_inferred[i].find(\"Thunderstorm\") != -1:\n",
    "        print i\n",
    "        count +=1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n"
     ]
    }
   ],
   "source": [
    "original = list(df_2015[\" Events\"])\n",
    "#print original\n",
    "print len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(572, 0.6407035175879396)\n"
     ]
    }
   ],
   "source": [
    "print(evaluation(Z_inferred[0:4000], original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noinfo\n",
      "(175, 0.813034188034188)\n",
      "Fog-Rain\n",
      "(27, 0.5178571428571428)\n",
      "Snow\n",
      "(30, 0.3877551020408163)\n",
      "Fog-Snow\n",
      "(10, 0.6666666666666667)\n",
      "Fog\n",
      "(6, 0.7777777777777778)\n",
      "Rain-Snow\n",
      "(42, 0.25)\n",
      "Fog-Rain-Snow\n",
      "(11, 0.3529411764705882)\n",
      "Rain\n",
      "(250, 0.30939226519337015)\n",
      "Thunderstorm\n",
      "(21, 0.6440677966101696)\n"
     ]
    }
   ],
   "source": [
    "targets = ['noinfo',\n",
    " 'Fog-Rain',\n",
    " 'Snow',\n",
    " 'Fog-Snow',\n",
    " 'Fog',\n",
    " 'Rain-Snow',\n",
    " 'Fog-Rain-Snow',\n",
    " 'Rain',\n",
    " \"Thunderstorm\"]\n",
    "for target in targets:\n",
    "    print target\n",
    "    print(evaluation(Z_inferred[0:4000], original, specific_target=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noinfo',\n",
       " 'Fog-Rain',\n",
       " 'Snow',\n",
       " 'Fog-Snow',\n",
       " 'Fog',\n",
       " 'Rain-Snow',\n",
       " 'Fog-Rain-Snow',\n",
       " 'Rain',\n",
       " 'Fog-Rain-Thunderstorm',\n",
       " 'Fog-Rain-Snow-Thunderstorm',\n",
       " 'Rain-Thunderstorm',\n",
       " 'Rain-Snow-Thunderstorm',\n",
       " 'Fog-Snow-Thunderstorm',\n",
       " 'Thunderstorm',\n",
       " 'Fog-Thunderstorm',\n",
       " 'Fog-Rain-Snow-Hail-Thunderstorm',\n",
       " 'Fog-Rain-Hail-Thunderstorm',\n",
       " 'Tornado',\n",
       " 'Rain-Hail-Thunderstorm']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[\" Events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
